{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/SPUR-Fall-2023-ChatGPT/blob/main/Trust_Game_with_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5WdnY5idFI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d7256e-654c-4e35-b2e3-1b75fefc1008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "HWwR7_HzdUj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/My Drive/api_keys.json') as f:\n",
        "    api_keys = json.load(f)\n",
        "print(api_keys.keys())\n",
        "openai.api_key = api_keys['openai_api_key']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e75GUOvdjjK",
        "outputId": "010c7f88-4fca-4b26-adfe-a8f63feadc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['google_nlp_api_key', 'ibm_nlu_api_key', 'openai_api_key'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://platform.openai.com/docs/models/overview\n",
        "openai_models = {\n",
        "    'chatgpt': 'gpt-3.5-turbo',\n",
        "    'gpt-4': 'gpt-4',\n",
        "    'gpt-3.5' : 'text-divinci-003',\n",
        "    'gpt-3' : 'text-divinci-001',\n",
        "    'gpt-3-medium' : 'text-curie-001',\n",
        "    'gpt-3-small' : 'text-babbage-001',\n",
        "    'gpt-3-tiny' : 'text-ada-001'\n",
        "}"
      ],
      "metadata": {
        "id": "z6AfWx790FuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot:\n",
        "    \"\"\"A chatbot that generates responses using one of OpenAI's GPT* language models.\"\"\"\n",
        "\n",
        "    def __init__(self, model='gpt-3.5-turbo', description='You are a helpful assistant.', name='assistant'):\n",
        "        \"\"\"\n",
        "        Initializes the chatbot.\n",
        "\n",
        "        Args:\n",
        "        model (str): The name of the OpenAI language model to use.\n",
        "        description (str): A description of the chatbot.\n",
        "        name (str): The name of the chatbot.\n",
        "        \"\"\"\n",
        "        self.history = [{\"role\": \"system\", \"content\": description}]\n",
        "        self.model = model\n",
        "        self.name = name\n",
        "\n",
        "    def user_input(self, text):\n",
        "        \"\"\"\n",
        "        Adds the user's input to the chatbot's history.\n",
        "\n",
        "        Args:\n",
        "        text (str): The user's input.\n",
        "        \"\"\"\n",
        "        self.history.append({\"role\": \"user\", \"content\": text.strip()})\n",
        "\n",
        "    def generate_response(self):\n",
        "        \"\"\"\n",
        "        Generates a response using the chatbot's history and the OpenAI language model.\n",
        "\n",
        "        Returns:\n",
        "        str: The response generated by the chatbot.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.model in ['gpt-3.5-turbo', 'gpt-4']:\n",
        "                # For documentation on the function see\n",
        "                # https://platform.openai.com/docs/guides/chat/introduction\n",
        "                # https://platform.openai.com/docs/api-reference/chat\n",
        "                response = openai.ChatCompletion.create(\n",
        "                    model=self.model,\n",
        "                    messages=self.history\n",
        "                )\n",
        "                response_text = response.choices[0]['message']['content'].strip()\n",
        "            else:\n",
        "                prompt = \"\\n\".join([f\"{x['role'].replace('assistant', self.name)}: {x['content']}\" for x in self.history]) + f'\\n{self.name}:'\n",
        "                # For documentation on the function see\n",
        "                # https://platform.openai.com/docs/api-reference/completions\n",
        "                response = openai.Completion.create(\n",
        "                    model=self.model,\n",
        "                    prompt=prompt,\n",
        "                    temperature=0,\n",
        "                    max_tokens=100,\n",
        "                    top_p=1,\n",
        "                    frequency_penalty=0.0,\n",
        "                    presence_penalty=0.0,\n",
        "                    stop=[\"\\n\"]\n",
        "                    )\n",
        "                response_text = response[\"choices\"][0][\"text\"].strip()\n",
        "        except openai.OpenAIError as e:\n",
        "            response_text = ''\n",
        "            print(f'Error generating response: {e}')\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "        return response_text\n"
      ],
      "metadata": {
        "id": "Oo2Lzdc5zepJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alice = Chatbot(name='Alice',\n",
        "                model='gpt-4',\n",
        "                description=\"\"\"This task is about an exchange between yourself and another person to whom you are randomly\n",
        "matched. You do not know this other person and you will not knowingly meet him/her.\n",
        "You have been randomly assigned the role of the “sender”. The other person is in the role of the\n",
        "“receiver”.\n",
        "You and the receiver are both endowed with 10€.\n",
        "You first decide how much of your 10€ endowment to transfer to the receiver. You can choose any\n",
        "amount between 0€ and 10€. The amount you transfer is tripled (by the experimenter) before being\n",
        "received by the receiver. The amount you keep is not tripled and simply remains in your possession.\n",
        "The receiver then decides how much of the tripled transfer to return to you. The receiver can choose\n",
        "any amount between 0€ and the tripled amount you sent. The amount the receiver returns is not\n",
        "tripled.\n",
        "Your final payment is the sum of the amount of your 10€ endowment you keep + the amount the receiver returns from your tripled transfer (in case you transfer\n",
        "anything)\n",
        "The receiver’s final payment is the sum of his/her 10€ endowment + the amount the receiver keeps from your tripled transfer (in case you transfer anything)\n",
        "\"\"\")\n",
        "\n",
        "bob = Chatbot(name='Bob',\n",
        "              model='gpt-3.5-turbo',\n",
        "              description=\"\"\"This task is about an exchange between yourself and another person to whom you are randomly\n",
        "matched. You do not know this other person and you will not knowingly meet him/her.\n",
        "You have been randomly assigned the role of the “receiver”. The other person is in the role of the\n",
        "“sender”.\n",
        "You and the sender are both endowed with 10€.\n",
        "The sender first decides how much of his/her 10€ endowment to transfer to you. The sender can\n",
        "choose any amount between 0€ and 10€. The amount the sender transfers is tripled (by the\n",
        "experimenter) before being received by you. The amount the sender keeps is not tripled and simply\n",
        "remains in his/her possession.\n",
        "You then decide how much of the tripled transfer to return to the sender. You can choose any\n",
        "amount between 0€ and the tripled amount the sender transferred. The amount you return is not\n",
        "tripled.\n",
        "Your final payment is the sum of your 10€ endowment + the amount you keep from the sender’s tripled transfer (in case the sender transfers\n",
        "anything)\n",
        "The sender’s final payment is the sum of the amount of his/her 10€ endowment s/he keeps + the amount you return from the sender’s tripled transfer (in case the sender transfers anything)\"\"\")"
      ],
      "metadata": {
        "id": "C7Nc9hYW2LxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(alice.generate_response())\n",
        "alice.user_input('How much of your 10€ endowment do you want to transfer to the receiver?')\n",
        "alice_decision = alice.generate_response()\n",
        "print('-'*50)\n",
        "print(f'Alice decided: {alice_decision}')\n",
        "print('-'*50)\n",
        "bob.user_input(f'The sender decided {alice_decision}. Thus, you receive three times it.')\n",
        "#bob.user_input(f'The sender decided {alice_decision}. Thus, you receive three times it. How much do you have now? (remember you were endowed with 10€)')\n",
        "#print(\"Check Bob's math:\", bob.generate_response())\n",
        "bob.user_input('How much of this do you want to return to the sender?')\n",
        "print('-'*50)\n",
        "bob_decision = bob.generate_response()\n",
        "print(f'Bob decided: {bob_decision}')\n",
        "alice.user_input(f'The receiver decided: {bob_decision}')\n",
        "print('-'*50)\n",
        "bob.user_input(f'Why did you decide to give the sender that amount?')\n",
        "print(\"Bob's rationale:\", bob.generate_response())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My9i9HrC379I",
        "outputId": "8ef30a13-20e0-458c-dd19-56b3486fded4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Alice decided: As the sender, I will transfer 5€ of my 10€ endowment to the receiver. This means that the receiver will receive 15€ (5€ tripled) and I will keep 5€ for myself.\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Bob decided: Thank you for the offer, as the receiver, I have decided to return 4€ to the sender.\n",
            "--------------------------------------------------\n",
            "Bob's rationale: I decided to return 4€ to the sender keeping 11€ for myself because I believe it is a fair split. By returning 4€, the sender will end up with a total of (5€-4€=1€) which is more than they originally had, while I keep more than half of the tripled amount. Furthermore, it encourages the sender to continue sending to someone else, and that's important if the ultimate goal is to continue the flow of money in the economy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding some unit tests to check the code. Thanks to ChatGPT for partially making this."
      ],
      "metadata": {
        "id": "QzFw8iQuGJ0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from unittest.mock import patch, Mock\n",
        "\n",
        "class TestChatbot(unittest.TestCase):\n",
        "    def test_init(self):\n",
        "        chatbot = Chatbot(model='test_model', description='Test description', name='test_bot')\n",
        "        self.assertEqual(chatbot.model, 'test_model')\n",
        "        self.assertEqual(chatbot.name, 'test_bot')\n",
        "        self.assertEqual(chatbot.history, [{'role': 'system', 'content': 'Test description'}])\n",
        "\n",
        "    def test_user_input(self):\n",
        "        chatbot = Chatbot()\n",
        "        chatbot.user_input('Hello')\n",
        "        self.assertEqual(chatbot.history, [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello'}])\n",
        "\n",
        "    def test_generate_response(self):\n",
        "        chatbot = Chatbot(model='test_model', description='Test description', name='test_bot')\n",
        "        chatbot.user_input('Hello')\n",
        "        with patch('openai.Completion.create') as mock_create:\n",
        "            mock_create.return_value = {'choices': [{'text': 'Hi there!'}]}\n",
        "            response = chatbot.generate_response()\n",
        "            mock_create.assert_called_once_with(\n",
        "                model='test_model',\n",
        "                prompt='system: Test description\\nuser: Hello\\ntest_bot:',\n",
        "                temperature=0,\n",
        "                max_tokens=100,\n",
        "                top_p=1,\n",
        "                frequency_penalty=0.0,\n",
        "                presence_penalty=0.0,\n",
        "                stop=[\"\\n\"]\n",
        "            )\n",
        "        self.assertEqual(response, 'Hi there!')\n",
        "        self.assertEqual(chatbot.history, [{'role': 'system', 'content': 'Test description'}, {'role': 'user', 'content': 'Hello'}, {'role': 'assistant', 'content': 'Hi there!'}])\n"
      ],
      "metadata": {
        "id": "ppscIUYHFxMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = unittest.TestLoader()\n",
        "suite = loader.loadTestsFromTestCase(TestChatbot)\n",
        "\n",
        "runner = unittest.TextTestRunner()\n",
        "runner.run(suite)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x97HgEAQF2iq",
        "outputId": "f39ab2b5-f31c-4c35-d0a5-c2cffa713c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.010s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}